{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7dzZc_rYrhN"
   },
   "source": [
    "# CNN   small datasets 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZSgQnWLYrhV"
   },
   "source": [
    "- 딥러닝 모델은 대용량 데이터를 학습할 때 좋은 성능이 나온다. 그래서 학습할 Data가 적을 경우 좋은 성능을 내기가 어렵다.\n",
    "  - 딥러닝은 **다양한 패턴의 많은 개수**의 데이터를 통해 feature engineering 과정 없이 원하는 문제를 해결하는 모델이다.\n",
    "- Data가 많지 않아 학습에 어려움이 있을 때 사용 가능한 방법.\n",
    "    1. **Data augmentation 활용**\n",
    "        - 기존 데이터를 변경하여 데이터 개수를 늘린다.\n",
    "        - 이미지의 경우 원본 이미지의 색깔, 각도 등을 약간씩 변형한 이미지들을 추가로 만들어 data의 수를 늘린다.\n",
    "    2. **Pre-trained network의 활용**\n",
    "        - 매우 큰 데이터셋으로 미리 Training한 모델의 파라미터(가중치)를 가져와서 풀려는 문제에 맞게 모델을 재보정해서 사용한다.\n",
    "        - 성능이 좋은 학습된 모델을 사용하므로 적은 데이터에도 좋은 성능을 낼 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8vvonb2YrhW"
   },
   "source": [
    "## Data for cats vs. dogs\n",
    "- 2013년 Kaggle의 computer vision competition data 활용 https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "- 개와 고양이를 구분하기 위한 문제로 각 12,500개의 이미지를 포함\n",
    "- Medium-resolution color JPEGs\n",
    "- 25000장의 사진 중 4000장의 cats/dogs 사진(2000 cats, 2000 dogs) 만을 사용하여 학습하여 좋은 모형을 만들어 낼 수 있을까?\n",
    "    - 학습: 2000, 검증: 1000, 테스트: 1000\n",
    "    \n",
    "![cats_vs_dogs_samples](https://s3.amazonaws.com/book.keras.io/img/ch5/cats_vs_dogs_samples.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz3IRzELYrhX"
   },
   "source": [
    "##### 이미지 다운로드\n",
    "- gdown 패키지 : 구글 드라이브의 공유파일 다운로드 패키지    \n",
    "- `pip install gdown`\n",
    "- 코랩에는 설치 되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:23:26.323854Z",
     "start_time": "2023-07-18T04:23:22.669679Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4800,
     "status": "ok",
     "timestamp": 1677483439954,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "zditZdln7tZN",
    "outputId": "90d94387-08ad-4877-e310-4c7a21e6e250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting filelock (from gdown)\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "                                              0.0/77.1 kB ? eta -:--:--\n",
      "     -----                                    10.2/77.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.1/77.1 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from requests[socks]->gdown) (2023.5.7)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\qkrtn\\anaconda3\\envs\\ml\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Installing collected packages: tqdm, PySocks, filelock, gdown\n",
      "Successfully installed PySocks-1.7.1 filelock-3.12.2 gdown-4.7.1 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:23:31.251417Z",
     "start_time": "2023-07-18T04:23:30.964190Z"
    },
    "id": "dvrTkPMS8R5K"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "from zipfile import ZipFile # zip압축 풀기/하기\n",
    "import os\n",
    "\n",
    "def down_extract():\n",
    "    url = 'https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV'\n",
    "    fname = 'cats_and_dogs_small.zip'   # 다운받아서 저장할 파일 이름.\n",
    "    # 다운로드\n",
    "    gdown.download(url, fname, quiet=False)\n",
    "    # 압축풀기\n",
    "    with ZipFile(fname) as zipFile: # 압축파일의 경로를 넣어서  ZipFile 객체 생성\n",
    "        zipFile.extractall('data/cats_and_dogs_small')  # 압축 풀 디렉토리 넣어서 실행. / extractall: 전체압축풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:23:43.465015Z",
     "start_time": "2023-07-18T04:23:32.155134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2893,
     "status": "ok",
     "timestamp": 1677483446063,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "NfaqyC9Q-ESz",
    "outputId": "5bbe3789-00ce-4880-d0b3-58518be49154"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV\n",
      "From (redirected): https://drive.google.com/uc?id=1YIxDL0XJhhAMdScdRUfDgccAqyCw5-ZV&confirm=t&uuid=b0500c67-4c8a-4ee3-9749-12447c374a25\n",
      "To: C:\\Users\\qkrtn\\classes\\02_DL\\cats_and_dogs_small.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 90.8M/90.8M [00:02<00:00, 33.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "down_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwpGLGo1f9F-"
   },
   "source": [
    "# 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:04.906344Z",
     "start_time": "2023-07-18T04:24:04.891412Z"
    },
    "id": "BkqMob8E7tZQ"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "N_EPOCH = 1\n",
    "N_BATCH = 100 # 에폭당 스텝수를 보면 한스텝이 100개씩 돌아간것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zBEjjWgYrha"
   },
   "source": [
    "## 모델 구현 및 학습\n",
    "\n",
    "- Input: $224 \\times 224$ 픽셀의 RGB layer \n",
    "- Output: cat or dog (binary classification)  \n",
    "- ImageDataGenerator를 이용해 파일시스템에 저장된 이미지 데이터셋을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:12.192598Z",
     "start_time": "2023-07-18T04:24:07.309116Z"
    },
    "id": "2Q5QMdVt7tZS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:14.455810Z",
     "start_time": "2023-07-18T04:24:14.437248Z"
    },
    "id": "G25uHSQNUi2N"
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "def get_model():\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(padding='same'))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # output layer: 이진분류 -> positive일 확률을 출력. unit=1, activation=sigmoid\n",
    "    model.add(layers.Dense(units=1, activation='sigmoid', name='binary_classification_output'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRGa9ay4eAx6"
   },
   "source": [
    "# ImageDataGenerator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\qkrtn\\\\classes\\\\02_DL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:17.179271Z",
     "start_time": "2023-07-18T04:24:17.171843Z"
    },
    "id": "56TWLKJxW_uJ"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 경로\n",
    "trainset_dir = 'data/cats_and_dogs_small/train'\n",
    "valset_dir = 'data/cats_and_dogs_small/validation/'\n",
    "testset_dir = 'data/cats_and_dogs_small/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:18.847011Z",
     "start_time": "2023-07-18T04:24:18.492625Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1677477831393,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "UWa-K0cG7tZT",
    "outputId": "779a1013-954f-4b96-c645-18ae2e3afaef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image augmentation 적용하지 않음.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Iterator 생성->raw data파일과 연결.\n",
    "train_iter = train_datagen.flow_from_directory(trainset_dir, # 이미지데이터셋이 저장된 디렉토리 / 이거랑 연결해야해! \n",
    "                                               target_size=(224,224), # 이미지를 읽어올 때 사이즈가 다르므로 resize크기 정하는것.\n",
    "                                               class_mode='binary',# output(y)의 처리방식-이진분류 / 다중분류할지 이진 분류할지 정하는것.\n",
    "                                               batch_size=N_BATCH # 배치 크기. 한번에 몇개씩 읽어와서 모델에 주입할지.\n",
    "                                               )\n",
    "\n",
    "val_iter = val_datagen.flow_from_directory(valset_dir, target_size=(224, 224), class_mode='binary', batch_size=N_BATCH)\n",
    "test_iter = test_datagen.flow_from_directory(testset_dir, target_size=(224, 224), class_mode='binary', batch_size=N_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:27.199837Z",
     "start_time": "2023-07-18T04:24:27.180437Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1677477831393,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "eYyEBXUiZyE_",
    "outputId": "dd1b67fb-4ffc-4b00-c0e3-0c53a7a4aff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==class index-class name확인\n",
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"==class index-class name확인\")\n",
    "print(train_iter.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:24:31.181094Z",
     "start_time": "2023-07-18T04:24:31.173735Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1677477831393,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "mKatIZUNZ6hO",
    "outputId": "d4846d64-59cf-42c3-96dc-0a48c97fad6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==에폭당 step 수\n",
      "20 10 10\n"
     ]
    }
   ],
   "source": [
    "print('==에폭당 step 수')\n",
    "print(len(train_iter), len(val_iter), len(test_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIfzRaBOYrhj"
   },
   "source": [
    "\n",
    "##  Model Training(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:29:29.188091Z",
     "start_time": "2023-07-18T04:29:29.171383Z"
    },
    "id": "kiUlSLsZ7tZU"
   },
   "outputs": [],
   "source": [
    "g_drive_path = '/content/drive/MyDrive/' # 구글 드라이브에서 저장할 때 사용하는 것.\n",
    "save_dir_path = os.path.join(g_drive_path, 'SAVED_MODELS', 'cat_dog_model_no_aug')\n",
    "os.makedirs(save_dir_path, exist_ok=True)\n",
    "\n",
    "save_weight_path = os.path.join(save_dir_path, 'ckpt')\n",
    "\n",
    "mc_callback = keras.callbacks.ModelCheckpoint(filepath=save_weight_path, \n",
    "                                              save_weights_only=True, # 파라미터(가중치)만 저장\n",
    "                                              save_best_only=True,# 성능이 좋은 것\n",
    "                                              monitor='val_loss',\n",
    "                                              verbose=1)\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:31:42.723611Z",
     "start_time": "2023-07-18T04:29:35.235120Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301838,
     "status": "ok",
     "timestamp": 1677478139838,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "G7s9iKn1cz5t",
    "outputId": "f9d405ca-4823-4c38-f599-a0df8e8ba4b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 120s 6s/step - loss: 0.6935 - accuracy: 0.5160 - val_loss: 0.6907 - val_accuracy: 0.5190\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "hist = model.fit(train_iter, epochs=N_EPOCH,\n",
    "                 steps_per_epoch=len(train_iter),\n",
    "                 validation_data=val_iter, \n",
    "                 validation_steps=len(val_iter),\n",
    "#                  callbacks=[mc_callback, es_callback]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:32:01.200539Z",
     "start_time": "2023-07-18T04:32:00.410809Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1677479082855,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "S9XoQeNDczwi",
    "outputId": "a884cdd1-7afd-404b-9c5d-b61b885a12c8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hist.epoch, hist.history['loss'], label='train')\n",
    "plt.plot(hist.epoch, hist.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1631154596465,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17974227978557155744"
     },
     "user_tz": -540
    },
    "id": "W7zoPdxDYw_D"
   },
   "source": [
    "##### 저장된 모델 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:32:28.371451Z",
     "start_time": "2023-07-18T04:32:11.633224Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6085,
     "status": "ok",
     "timestamp": 1677479285824,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "mIdENT0L7tZV",
    "outputId": "e0314bcb-843b-48c3-faf9-bf76eb7010dc"
   },
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "saved_model1 = get_model()\n",
    "saved_model1.evaluate(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:32:43.605323Z",
     "start_time": "2023-07-18T04:32:31.314179Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1677479371210,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "_NU4Zd3ejrRW",
    "outputId": "b5ad56de-c983-4fad-acda-d748ffb2480b"
   },
   "outputs": [],
   "source": [
    "# 새로 생성된 모델에 저장 best wegith 덮어씌우기\n",
    "saved_model1.load_weights(save_weight_path)\n",
    "\n",
    "saved_model1.evaluate(test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPb0Ky5jZ9uU"
   },
   "source": [
    "# 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:33:32.451325Z",
     "start_time": "2023-07-18T04:33:32.442920Z"
    },
    "id": "iOnFXKugllVm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_preprocessing(image_path):\n",
    "    \"\"\"\n",
    "    경로의 이미지를 읽어서 전처리(scaling) 한 뒤 반환.\n",
    "    [Parameter]\n",
    "       image_path: str - 변환할 이미지 경로(Path)\n",
    "    [Return]\n",
    "       ndarray: 전처리한 이미지\n",
    "    \"\"\"\n",
    "    raw_img = load_img(image_path, target_size=(224,224))\n",
    "    img_array = img_to_array(raw_img)\n",
    "    img_array = img_array[np.newaxis, ...]\n",
    "    img_array = img_array.astype('float32')/255\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:33:33.479710Z",
     "start_time": "2023-07-18T04:33:33.138076Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677480275139,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "swskb-I87tZV",
    "outputId": "6ce14c8c-ac60-4721-889f-e1c186096c44"
   },
   "outputs": [],
   "source": [
    "new_img_path = 'dog.jpg'\n",
    "new_X = load_preprocessing(new_img_path)\n",
    "\n",
    "pred = saved_model1.predict(new_X)\n",
    "print(pred)\n",
    "print(np.where(pred>=0.5, \"개\", \"고양이\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fAwTvdIYrhm"
   },
   "source": [
    "# Image data augmentation 사용\n",
    "\n",
    "- 학습 이미지의 수가 적어서 overfitting이 발생할 가능성을 줄이기 위해 기존 훈련 데이터로부터 그럴듯하게 이미지 변환을 통해서 이미지(데이터)를 늘리는 작업을 Image augmentation\n",
    "- train_set에만 적용, validation, test set에는 적용하지 않는다. (rescaling만 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1631165833848,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17974227978557155744"
     },
     "user_tz": -540
    },
    "id": "VLlmQOu7WqrP"
   },
   "source": [
    "##### 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Twoi5hPj7tZW"
   },
   "source": [
    "##### ImageDataGenerator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:33:47.643121Z",
     "start_time": "2023-07-18T04:33:47.623864Z"
    },
    "id": "G9Z1V9rq7tZW"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 경로\n",
    "trainset_dir = 'data/cats_and_dogs_small/train'\n",
    "valset_dir = 'data/cats_and_dogs_small/validation/'\n",
    "testset_dir = 'data/cats_and_dogs_small/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:33:48.404798Z",
     "start_time": "2023-07-18T04:33:48.394820Z"
    },
    "id": "PoJUgbl4t6wf"
   },
   "outputs": [],
   "source": [
    "# Image Augmentation 적용. ==> Train set에만 적용.\n",
    "train_datagen2 = ImageDataGenerator(rescale=1./255, \n",
    "                                    rotation_range=40, \n",
    "                                    width_shift_range=0.2, \n",
    "                                    height_shift_range=0.2, \n",
    "                                    zoom_range=0.2, \n",
    "                                    horizontal_flip=True, \n",
    "                                    fill_mode='constant')\n",
    "\n",
    "val_datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen2 = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:33:50.342886Z",
     "start_time": "2023-07-18T04:33:50.002130Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1677485871774,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "wZ9YWljTu_jQ",
    "outputId": "9d0bc067-2fe9-4c4f-efdc-8260a41627ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iter2 = train_datagen2.flow_from_directory(trainset_dir, target_size=(224,224), class_mode='binary', \n",
    "                                                 batch_size=N_BATCH)\n",
    "\n",
    "val_iter2 = val_datagen2.flow_from_directory(valset_dir, target_size=(224,224), class_mode='binary', batch_size=N_BATCH)\n",
    "\n",
    "test_iter2 = test_datagen2.flow_from_directory(testset_dir, target_size=(224,224), class_mode='binary', batch_size=N_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1631158426700,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17974227978557155744"
     },
     "user_tz": -540
    },
    "id": "NI8tn-1cWqrR"
   },
   "source": [
    "##### 모델 생성, 컴파일, 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:36:19.990510Z",
     "start_time": "2023-07-18T04:33:56.547385Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1427271,
     "status": "ok",
     "timestamp": 1677488925547,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "TOdsKmnu7tZX",
    "outputId": "ce3dbc94-427b-466c-d14e-28120cb74db2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 128s 6s/step - loss: 0.6949 - accuracy: 0.5040 - val_loss: 0.6933 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# # g_drive_path = '/content/drive/MyDrive'\n",
    "# save_dir_path = os.path.join(g_drive_path, \"saved_model\", \"cat_dog_model_aug\")\n",
    "# mc_callback2 = keras.callbacks.ModelCheckpoint(save_dir_path, save_best_only=True, monitor='val_loss', verbose=1)\n",
    "# es_callback2 = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "\n",
    "model2 = get_model()\n",
    "\n",
    "hist2 = model2.fit(train_iter2, epochs=N_EPOCH, \n",
    "                   steps_per_epoch=len(train_iter2), # 학습시 1에폭당 step수 => 1에폭이 언제 끝났는지 알려준다.\n",
    "                   validation_data=val_iter2, \n",
    "                   validation_steps=len(val_iter2),) # 검증시 1에폭당 step수 \n",
    "#                    callbacks=[mc_callback2, es_callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:36:24.450526Z",
     "start_time": "2023-07-18T04:36:24.185107Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1677489222766,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "AzOroweXyaZ1",
    "outputId": "b78f2e48-bcbd-4931-a1bb-c6ed7338042d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(hist2.epoch, hist2.history['loss'], label='train')\n",
    "plt.plot(hist2.epoch, hist2.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_dlXsnp7tZX"
   },
   "source": [
    "##### 저장된 모델 Loading 후 평가(사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:36:47.885459Z",
     "start_time": "2023-07-18T04:36:47.146297Z"
    },
    "executionInfo": {
     "elapsed": 3002,
     "status": "ok",
     "timestamp": 1677544108119,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "dVJuQ_DIaXIW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "saved_model2 = models.load_model(save_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1631166141746,
     "user": {
      "displayName": "김성환",
      "photoUrl": "",
      "userId": "17974227978557155744"
     },
     "user_tz": -540
    },
    "id": "o4sSoGQXlJKX"
   },
   "source": [
    "##### 새로운데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:36:51.551558Z",
     "start_time": "2023-07-18T04:36:51.545307Z"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1677544418004,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "rIzZvNi67tZX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_preprocessing_image(path):\n",
    "    raw_img = load_img(path, target_size=(224, 224))  #이미지 읽어오기\n",
    "    img_array = img_to_array(raw_img)\n",
    "    img_array = img_array[np.newaxis, ...]\n",
    "    img_array = img_array.astype('float32')/255\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T04:36:56.339252Z",
     "start_time": "2023-07-18T04:36:56.099066Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677544641692,
     "user": {
      "displayName": "encore엔코아",
      "userId": "03488190351334320755"
     },
     "user_tz": -540
    },
    "id": "Q_RxaHUlbef8",
    "outputId": "1fd7158f-c605-4119-d850-e0f6b2135498"
   },
   "outputs": [],
   "source": [
    "img_path = 'dog.jpg'\n",
    "data = load_preprocessing_image(img_path)\n",
    "# data.shape\n",
    "pred = saved_model2.predict(data)\n",
    "pred_label = np.where(pred[0]>=0.5, \"개\", \"고양이\")\n",
    "print(pred[0], pred_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
